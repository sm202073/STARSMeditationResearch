{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from collections import Counter\n",
    "import glob\n",
    "import os\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Paths for all the different corpora\n",
    "folderpaths = ['../AnxietyMeditations/', '../SleepMeditations/',\n",
    "               '../LearningAndGrowthMeditations/', '../MorningMeditations/']\n",
    "\n",
    "#array to store the text of each file \n",
    "corpus = []\n",
    "\n",
    "for folder in folderpaths:\n",
    "    if folder == '../AnxietyMeditations/':\n",
    "        for doc in glob.glob(os.path.join(folder, '*.txt')):\n",
    "            with open(doc, 'r') as f:\n",
    "                text = f.read()\n",
    "                corpus.append(text)\n",
    "    elif folder == '../SleepMeditations/':\n",
    "        for doc in glob.glob(os.path.join(folder, '*.txt')):\n",
    "            with open(doc, 'r') as f:\n",
    "                text = f.read()\n",
    "                corpus.append(text)\n",
    "    elif folder == '../LearningAndGrowthMeditations/':\n",
    "        for doc in glob.glob(os.path.join(folder, '*.txt')):\n",
    "            with open(doc, 'r') as f:\n",
    "                text = f.read()\n",
    "                corpus.append(text)\n",
    "    elif folder == '../MorningMeditations/':\n",
    "        for doc in glob.glob(os.path.join(folder, '*.txt')):\n",
    "            with open(doc, 'r') as f:\n",
    "                text = f.read()\n",
    "                corpus.append(text)\n",
    "\n",
    "newStopWords = ['[', ']', '`', '#', '$',\n",
    "                '(', ')', \"Music\", ':', \"....\", \"--\", \",\", \"''\", '`', '\"']\n",
    "stopwords = set(stopwords.words('english') +\n",
    "                newStopWords + list(string.punctuation))\n",
    "\n",
    "# Tokenizing by word and filtering stopwords\n",
    "all_tokens = [w for w in word_tokenize(text.lower()) if not w in stopwords]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Preprocess the text data\n",
    "tokenized_corpus = []\n",
    "for text in corpus:\n",
    "    # Tokenize and lowercase\n",
    "    tokens = [w for w in word_tokenize(text.lower()) if not w in stopwords]\n",
    "    tokenized_corpus.append(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.02653323  0.05852161  0.02017573  0.1153099   0.05651342 -0.04240022\n",
      "  0.10008867  0.06135989 -0.09201974  0.00315122 -0.02239042 -0.11175106\n",
      "  0.00291366 -0.04352164  0.01267677  0.04617912  0.01599739 -0.10696957\n",
      " -0.0088408  -0.24518044  0.00112012  0.10368763  0.11289176 -0.06273969\n",
      " -0.0327258   0.10308766 -0.0436478  -0.01422539 -0.15158582  0.02675248\n",
      "  0.0566883   0.0450117   0.05689706 -0.01731101 -0.11099516  0.10280446\n",
      " -0.01515267 -0.00413648 -0.06110399 -0.12861285  0.09279277 -0.03426292\n",
      " -0.01301743 -0.04958991  0.09139542 -0.0283929  -0.08201457  0.06720281\n",
      "  0.11337388  0.01212116 -0.01342705 -0.02875162  0.02750847  0.01119757\n",
      " -0.07837638  0.06387543  0.00919308 -0.0778852  -0.03149487 -0.03309042\n",
      "  0.03080989  0.04782719  0.07188828  0.01544644 -0.03641949  0.02229595\n",
      " -0.12686552  0.02959929 -0.11498702 -0.02038725 -0.00524906  0.10749009\n",
      "  0.00610576 -0.04100489  0.01839402 -0.00400722  0.03738354 -0.10490306\n",
      " -0.04024782 -0.04371351 -0.02251911 -0.06392628 -0.02784223  0.01901228\n",
      "  0.0180338  -0.07014816 -0.03532042  0.0019778   0.04207367  0.01744271\n",
      "  0.0379417   0.0953001  -0.07013328  0.04684348  0.13484494  0.01866818\n",
      " -0.03379294 -0.09988587  0.07251908 -0.002889  ]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "# Preprocess the text data\n",
    "tokenized_corpus = []\n",
    "for text in corpus:\n",
    "    tokens = word_tokenize(text.lower())  # Tokenize and lowercase\n",
    "    tokenized_corpus.append(tokens)\n",
    "\n",
    "context_windows = []\n",
    "window_size = 4  # Size of the context window\n",
    "\n",
    "for sentence in tokenized_corpus:\n",
    "    sentence_length = len(sentence)\n",
    "    for i in range(sentence_length):\n",
    "        # Extract the target word\n",
    "        target_word = sentence[i]\n",
    "\n",
    "        # Extract the context words within the window size\n",
    "        context_words = []\n",
    "        for j in range(max(0, i - window_size), min(sentence_length, i + window_size + 1)):\n",
    "            if j != i:\n",
    "                context_words.append(sentence[j])\n",
    "\n",
    "        # Append the target word and its context words as a tuple\n",
    "        # Convert context_words to tuple\n",
    "        context_windows.append((target_word, tuple(context_words)))\n",
    "\n",
    "# Train the Word2Vec model\n",
    "model = Word2Vec(context_windows, window=5,\n",
    "                 min_count=10, sg=0)  # CBOW approach\n",
    "\n",
    "# Accessing trained word vectors\n",
    "word_vector = model.wv['breathe']  # Get the word vector for a specific word\n",
    "print(word_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nltk\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Define the directory containing the text files\n",
    "directory = \"./txt Files/\"\n",
    "\n",
    "all_vectors = {}\n",
    "\n",
    "# Iterate over the files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        with open(filepath, \"r\") as f:\n",
    "            text = f.read()\n",
    "            words = nltk.word_tokenize(text)\n",
    "            for word in words:\n",
    "                try:\n",
    "                    word_vector = model.wv[word.lower()]\n",
    "                    all_vectors[filename] = word_vector\n",
    "                    # print(f\"Word: {word}\\nVector: {word_vector}\\n\")\n",
    "                except KeyError:\n",
    "                    continue\n",
    "                    # print(f\"Word '{word}' not in vocabulary.\\n\")\n",
    "\n",
    "print(len(all_vectors['sight.txt']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance matrix for sound.txt:\n",
      "[[ 0.0000000e+00  2.0000000e+00  0.0000000e+00 ... -1.1920929e-07\n",
      "  -1.1920929e-07  0.0000000e+00]\n",
      " [ 2.0000000e+00  0.0000000e+00  2.0000000e+00 ...  2.0000000e+00\n",
      "   2.0000000e+00  2.0000000e+00]\n",
      " [ 0.0000000e+00  2.0000000e+00  0.0000000e+00 ... -1.1920929e-07\n",
      "   0.0000000e+00  0.0000000e+00]\n",
      " ...\n",
      " [-1.1920929e-07  2.0000000e+00 -1.1920929e-07 ...  5.9604645e-08\n",
      "  -1.1920929e-07  0.0000000e+00]\n",
      " [ 0.0000000e+00  2.0000000e+00  0.0000000e+00 ... -1.1920929e-07\n",
      "   0.0000000e+00  0.0000000e+00]\n",
      " [ 0.0000000e+00  2.0000000e+00  0.0000000e+00 ...  5.9604645e-08\n",
      "   0.0000000e+00  0.0000000e+00]]\n",
      "Distance matrix for taste.txt:\n",
      "[[-1.1920929e-07  0.0000000e+00 -1.1920929e-07 ...  2.0000000e+00\n",
      "   0.0000000e+00  2.0000000e+00]\n",
      " [ 0.0000000e+00  0.0000000e+00  5.9604645e-08 ...  2.0000000e+00\n",
      "   0.0000000e+00  2.0000000e+00]\n",
      " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  2.0000000e+00\n",
      "   0.0000000e+00  2.0000000e+00]\n",
      " ...\n",
      " [ 2.0000000e+00  2.0000000e+00  2.0000000e+00 ...  0.0000000e+00\n",
      "   2.0000000e+00  0.0000000e+00]\n",
      " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  2.0000000e+00\n",
      "   0.0000000e+00  2.0000000e+00]\n",
      " [ 2.0000000e+00  2.0000000e+00  2.0000000e+00 ...  0.0000000e+00\n",
      "   2.0000000e+00  0.0000000e+00]]\n",
      "Distance matrix for touch.txt:\n",
      "[[ 0.0000000e+00  2.0000000e+00  2.0000000e+00 ...  0.0000000e+00\n",
      "   2.0000000e+00 -1.1920929e-07]\n",
      " [ 2.0000000e+00  0.0000000e+00  0.0000000e+00 ...  2.0000000e+00\n",
      "   0.0000000e+00  2.0000000e+00]\n",
      " [ 2.0000000e+00  0.0000000e+00  0.0000000e+00 ...  2.0000000e+00\n",
      "   0.0000000e+00  2.0000000e+00]\n",
      " ...\n",
      " [ 0.0000000e+00  2.0000000e+00  2.0000000e+00 ...  0.0000000e+00\n",
      "   2.0000000e+00  0.0000000e+00]\n",
      " [ 2.0000000e+00  0.0000000e+00  0.0000000e+00 ...  2.0000000e+00\n",
      "   0.0000000e+00  2.0000000e+00]\n",
      " [-1.1920929e-07  2.0000000e+00  2.0000000e+00 ...  0.0000000e+00\n",
      "   2.0000000e+00  0.0000000e+00]]\n",
      "Distance matrix for smell.txt:\n",
      "[[ 0.0000000e+00 -1.1920929e-07  2.0000000e+00 ...  2.0000000e+00\n",
      "   0.0000000e+00  2.0000000e+00]\n",
      " [-1.1920929e-07  0.0000000e+00  2.0000000e+00 ...  2.0000000e+00\n",
      "   5.9604645e-08  2.0000000e+00]\n",
      " [ 2.0000000e+00  2.0000000e+00  0.0000000e+00 ...  5.9604645e-08\n",
      "   2.0000000e+00  0.0000000e+00]\n",
      " ...\n",
      " [ 2.0000000e+00  2.0000000e+00  0.0000000e+00 ...  0.0000000e+00\n",
      "   2.0000000e+00  0.0000000e+00]\n",
      " [ 0.0000000e+00  5.9604645e-08  2.0000000e+00 ...  2.0000000e+00\n",
      "   0.0000000e+00  2.0000000e+00]\n",
      " [ 2.0000000e+00  2.0000000e+00  0.0000000e+00 ...  0.0000000e+00\n",
      "   2.0000000e+00 -1.1920929e-07]]\n",
      "Distance matrix for sight.txt:\n",
      "[[0.0000000e+00 2.0000000e+00 2.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 2.0000000e+00]\n",
      " [2.0000000e+00 0.0000000e+00 0.0000000e+00 ... 2.0000000e+00\n",
      "  2.0000000e+00 0.0000000e+00]\n",
      " [2.0000000e+00 0.0000000e+00 0.0000000e+00 ... 2.0000000e+00\n",
      "  2.0000000e+00 0.0000000e+00]\n",
      " ...\n",
      " [0.0000000e+00 2.0000000e+00 2.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 2.0000000e+00]\n",
      " [0.0000000e+00 2.0000000e+00 2.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 2.0000000e+00]\n",
      " [2.0000000e+00 0.0000000e+00 0.0000000e+00 ... 2.0000000e+00\n",
      "  2.0000000e+00 5.9604645e-08]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define a function to compute cosine similarity distance matrix\n",
    "def cosine_sim_matrix(vectors):\n",
    "    vectors_array = np.array(vectors)\n",
    "    if vectors_array.ndim < 2:\n",
    "        # If vectors_array is 1D, add a new axis to make it 2D\n",
    "        vectors_array = vectors_array[:, np.newaxis]\n",
    "    cosine_sim = np.dot(vectors_array, vectors_array.T)\n",
    "    cosine_sim /= np.linalg.norm(vectors_array, axis=1, keepdims=True)\n",
    "    cosine_sim /= np.linalg.norm(vectors_array, axis=1, keepdims=True).T\n",
    "    distance_matrix = 1 - cosine_sim\n",
    "    return distance_matrix\n",
    "\n",
    "\n",
    "# Compute the cosine similarity distance matrix for each list of vectors in the dictionary\n",
    "distance_matrices = {}\n",
    "for key, vectors_list in all_vectors.items():\n",
    "    distance_matrix = cosine_sim_matrix(vectors_list)\n",
    "    distance_matrices[key] = distance_matrix\n",
    "\n",
    "# Print distance matrix for each key in the dictionary\n",
    "for key, distance_matrix in distance_matrices.items():\n",
    "    print(f\"Distance matrix for {key}:\")\n",
    "    print(distance_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "distance_pca = {}\n",
    "\n",
    "for key, distance_matrix in distance_matrices.items():\n",
    "    # Perform PCA to reduce the dimensionality of the distance matrix\n",
    "    pca = PCA(n_components=2)\n",
    "    pca.fit(distance_matrix)\n",
    "    distance_pca[key] = pca.transform(distance_matrix)\n",
    "\n",
    "print(distance_pca['taste.txt'].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# assume distance_pca is a dictionary mapping filenames to 2D arrays\n",
    "# representing the pairwise distances between word vectors after PCA\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# calculate mean distance between all pairs of points\n",
    "mean_dist = np.mean([np.linalg.norm(distance_pca[key][i] - distance_pca[key][j]) \n",
    "                     for key in distance_pca \n",
    "                     for i in range(len(distance_pca[key])) \n",
    "                     for j in range(i+1, len(distance_pca[key]))])\n",
    "\n",
    "# plot bar chart\n",
    "for i, key in enumerate(distance_pca):\n",
    "    x = i + 1\n",
    "    y = [np.linalg.norm(p) for p in distance_pca[key]]\n",
    "    ax.bar(x, height=y, width=mean_dist, label=key)\n",
    "\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
