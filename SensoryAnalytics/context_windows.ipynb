{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from collections import Counter\n",
    "import glob\n",
    "import os\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Paths for all the different corpora\n",
    "folderpaths = ['../AnxietyMeditations/', '../SleepMeditations/', '../LearningAndGrowthMeditations/', '../MorningMeditations/']\n",
    "\n",
    "# Strings to store text for each corpora and all corpora\n",
    "all_text = \"\"\n",
    "anxiety_text = \"\"\n",
    "sleep_text = \"\"\n",
    "learningNgrowth_text = \"\"\n",
    "morning_text = \"\"\n",
    "\n",
    "for folder in folderpaths:\n",
    "    if folder == '../AnxietyMeditations/':\n",
    "        for doc in glob.glob(os.path.join(folder, '*.txt')):\n",
    "            with open(doc, 'r') as f:\n",
    "                text = f.read()\n",
    "                anxiety_text += text\n",
    "                all_text += text\n",
    "    elif folder == '../SleepMeditations/':\n",
    "        for doc in glob.glob(os.path.join(folder, '*.txt')):\n",
    "            with open(doc, 'r') as f:\n",
    "                text = f.read()\n",
    "                sleep_text += text\n",
    "                all_text += text\n",
    "    elif folder == '../LearningAndGrowthMeditations/':\n",
    "        for doc in glob.glob(os.path.join(folder, '*.txt')):\n",
    "            with open(doc, 'r') as f:\n",
    "                text = f.read()\n",
    "                learningNgrowth_text += text\n",
    "                all_text += text\n",
    "    elif folder == '../MorningMeditations/':\n",
    "        for doc in glob.glob(os.path.join(folder, '*.txt')):\n",
    "            with open(doc, 'r') as f:\n",
    "                text = f.read()\n",
    "                morning_text += text\n",
    "                all_text += text\n",
    "    \n",
    "newStopWords = ['[', ']', '`', '#', '$', '(', ')', \"Music\", ':', \"....\", \"--\", \",\", \"''\", '`', '\"']\n",
    "stopwords = set(stopwords.words('english') + newStopWords + list(string.punctuation))\n",
    "\n",
    "# Tokenizing by word and filtering stopwords\n",
    "all_tokens = [w for w in word_tokenize(all_text) if not w in stopwords]\n",
    "anxiety_tokens = [w for w in word_tokenize(anxiety_text) if not w in stopwords]\n",
    "sleep_tokens = [w for w in word_tokenize(sleep_text) if not w in stopwords]\n",
    "learningNgrowth_tokens = [w for w in word_tokenize(learningNgrowth_text) if not w in stopwords]\n",
    "morning_tokens = [w for w in word_tokenize(morning_text) if not w in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking for words in data \n",
    "context_windows = []\n",
    "window_sizes = [4, 10, 15, 25]\n",
    "for window_size in window_sizes:\n",
    "    for i in range(len(all_tokens)):\n",
    "        context_window = all_tokens[max(0, i-window_size):i] + all_tokens[i+1:min(len(all_tokens), i+window_size)]\n",
    "        context_windows.append(context_window)\n",
    "\n",
    "print(context_windows[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6ecdebf77f2ee3a47348d003f751c63e810ca996c1c68d1179f338200fa83b34"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
