{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mm42.txt</td>\n",
       "      <td>hello welcome to today's gentle movement pract...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mm56.txt</td>\n",
       "      <td>take a load off right now set yourself down an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mm81.txt</td>\n",
       "      <td>holding on to negative thoughts and emotions c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mm95.txt</td>\n",
       "      <td>Find a comfortable position sitting or lying d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mm2.txt</td>\n",
       "      <td>welcome to this guided meditation but\\nwas thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>mm72.txt</td>\n",
       "      <td>- Hi everyone. Welcome to Yoga With Adriene.\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>mm99.txt</td>\n",
       "      <td>Our own self-talk can contribute to the pain a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>mm98.txt</td>\n",
       "      <td>Take a moment to settle into a comfortable pos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>mm73.txt</td>\n",
       "      <td>20 Minute Guided Meditation for Depression, An...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>mm67.txt</td>\n",
       "      <td>this meditation will provide you with\\nthe too...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    file_name                                               text\n",
       "0    mm42.txt  hello welcome to today's gentle movement pract...\n",
       "1    mm56.txt  take a load off right now set yourself down an...\n",
       "2    mm81.txt  holding on to negative thoughts and emotions c...\n",
       "3    mm95.txt  Find a comfortable position sitting or lying d...\n",
       "4     mm2.txt  welcome to this guided meditation but\\nwas thi...\n",
       "..        ...                                                ...\n",
       "96   mm72.txt  - Hi everyone. Welcome to Yoga With Adriene.\\n...\n",
       "97   mm99.txt  Our own self-talk can contribute to the pain a...\n",
       "98   mm98.txt  Take a moment to settle into a comfortable pos...\n",
       "99   mm73.txt  20 Minute Guided Meditation for Depression, An...\n",
       "100  mm67.txt  this meditation will provide you with\\nthe too...\n",
       "\n",
       "[101 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "file_names = os.listdir('../AnxietyMeditations/')\n",
    "# Create Dictionary for File Name and Text\n",
    "file_name_and_text = {}\n",
    "for file in file_names:\n",
    "    f = open('../AnxietyMeditations/' + file, \"r\",\n",
    "             encoding='unicode_escape')\n",
    "    file_name_and_text[file] = f.read()\n",
    "file_data = (pd.DataFrame.from_dict(file_name_and_text, orient='index')\n",
    "             .reset_index().rename(index=str, columns={'index': 'file_name', 0: 'text'}))\n",
    "\n",
    "file_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:997)>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import math\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.models import CoherenceModel\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from datetime import datetime\n",
    "import nltk\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>text</th>\n",
       "      <th>preprocessed_text</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mm42.txt</td>\n",
       "      <td>hello welcome to today's gentle movement pract...</td>\n",
       "      <td>hello welcome today's gentle movement practice...</td>\n",
       "      <td>[hello, welcome, today's, gentle, movement, pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mm56.txt</td>\n",
       "      <td>take a load off right now set yourself down an...</td>\n",
       "      <td>take load right set relax best moment fully ap...</td>\n",
       "      <td>[take, load, right, set, relax, best, moment, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mm81.txt</td>\n",
       "      <td>holding on to negative thoughts and emotions c...</td>\n",
       "      <td>holding negative thoughts emotions heavy creat...</td>\n",
       "      <td>[holding, negative, thoughts, emotions, heavy,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mm95.txt</td>\n",
       "      <td>Find a comfortable position sitting or lying d...</td>\n",
       "      <td>find comfortable position sitting lying down. ...</td>\n",
       "      <td>[find, comfortable, position, sitting, lying, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mm2.txt</td>\n",
       "      <td>welcome to this guided meditation but\\nwas thi...</td>\n",
       "      <td>welcome guided meditation thing present practi...</td>\n",
       "      <td>[welcome, guided, meditation, thing, present, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  file_name                                               text  \\\n",
       "0  mm42.txt  hello welcome to today's gentle movement pract...   \n",
       "1  mm56.txt  take a load off right now set yourself down an...   \n",
       "2  mm81.txt  holding on to negative thoughts and emotions c...   \n",
       "3  mm95.txt  Find a comfortable position sitting or lying d...   \n",
       "4   mm2.txt  welcome to this guided meditation but\\nwas thi...   \n",
       "\n",
       "                                   preprocessed_text  \\\n",
       "0  hello welcome today's gentle movement practice...   \n",
       "1  take load right set relax best moment fully ap...   \n",
       "2  holding negative thoughts emotions heavy creat...   \n",
       "3  find comfortable position sitting lying down. ...   \n",
       "4  welcome guided meditation thing present practi...   \n",
       "\n",
       "                                      tokenized_text  \n",
       "0  [hello, welcome, today's, gentle, movement, pr...  \n",
       "1  [take, load, right, set, relax, best, moment, ...  \n",
       "2  [holding, negative, thoughts, emotions, heavy,...  \n",
       "3  [find, comfortable, position, sitting, lying, ...  \n",
       "4  [welcome, guided, meditation, thing, present, ...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "en_stop_words = set(stopwords.words('english'))\n",
    "list(en_stop_words)[:10]\n",
    "\n",
    "def clean_tweets(df=file_data, \n",
    "                 text_col='text', \n",
    "                ):\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # drop rows with empty values\n",
    "    df_copy.dropna(inplace=True)\n",
    "    \n",
    "    # format the date\n",
    "    #df_copy[date_col] = df_copy[date_col].apply(lambda row: datetime.strptime(row, '%m-%d-%Y %H:%M:%S'))\n",
    "    \n",
    "    # filter rows older than a given date\n",
    "    #df_copy = df_copy[df_copy[date_col] >=start_datetime]\n",
    "    \n",
    "    # lower the tweets\n",
    "    df_copy['preprocessed_' + text_col] = df_copy[text_col].str.lower()\n",
    "    \n",
    "    # filter out stop words and URLs\n",
    "    en_stop_words = set(stopwords.words('english'))\n",
    "    en_stop_words.add('music')\n",
    "    extended_stop_words = en_stop_words | \\\n",
    "                        {\n",
    "                            '&amp;', 'rt',                           \n",
    "                            'th','co', 're', 've', 'kim', 'daca'\n",
    "                        }\n",
    "    url_re = '(https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]+\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]+\\.[^\\s]{2,})'        \n",
    "    df_copy['preprocessed_' + text_col] = df_copy['preprocessed_' + text_col].apply(lambda row: ' '.join(\n",
    "        [word for word in row.split() if (not word in en_stop_words) and (not re.match(url_re, word))]))\n",
    "    \n",
    "    # tokenize the tweets\n",
    "    tokenizer = RegexpTokenizer('[a-zA-Z]\\w+\\'?\\w*')\n",
    "    df_copy['tokenized_' + text_col] = df_copy['preprocessed_' + text_col].apply(lambda row: tokenizer.tokenize(row))\n",
    "    \n",
    "    return df_copy\n",
    "  \n",
    "#df_tweets = pd.read_csv('trump_tweets.csv')\n",
    "df_clean = clean_tweets(file_data)\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('body', 912),\n",
       " ('music', 911),\n",
       " ('breath', 803),\n",
       " ('let', 712),\n",
       " ('feel', 666),\n",
       " ('go', 643),\n",
       " ('allow', 426),\n",
       " ('take', 416),\n",
       " ('mind', 400),\n",
       " ('moment', 396)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_most_freq_words(str, n=None):\n",
    "    vect = CountVectorizer().fit(str)\n",
    "    bag_of_words = vect.transform(str)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    freq = [(word, sum_words[0, idx]) for word, idx in vect.vocabulary_.items()]\n",
    "    freq =sorted(freq, key = lambda x: x[1], reverse=True)\n",
    "    return freq[:n]\n",
    "  \n",
    "get_most_freq_words([ word for line in df_clean.tokenized_text for word in line],10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# build a dictionary where for each tweet, each word has its own id.\n",
    "# We have 6882 tweets and 10893 words in the dictionary.\n",
    "tweets_dictionary = Dictionary(df_clean.tokenized_text)\n",
    "\n",
    "# build the corpus i.e. vectors with the number of occurence of each word per tweet\n",
    "tweets_corpus = [tweets_dictionary.doc2bow(\n",
    "    tweet) for tweet in df_clean.tokenized_text]\n",
    "\n",
    "# compute coherence\n",
    "tweets_coherence = []\n",
    "for nb_topics in range(1, 36):\n",
    "    lda = LdaModel(tweets_corpus, num_topics=nb_topics,\n",
    "                   id2word=tweets_dictionary, passes=10)\n",
    "    cohm = CoherenceModel(model=lda, corpus=tweets_corpus,\n",
    "                          dictionary=tweets_dictionary, coherence='u_mass')\n",
    "    coh = cohm.get_coherence()\n",
    "    tweets_coherence.append(coh)\n",
    "\n",
    "# visualize coherence\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, 36), tweets_coherence)\n",
    "plt.xlabel(\"Number of Topics\")\n",
    "plt.ylabel(\"Coherence Score\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
